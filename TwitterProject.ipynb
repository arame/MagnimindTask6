{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91039f7c-4705-45ef-93f9-c84bcfcde8f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Deep Learning Project\n",
    "\n",
    "You have developed a model in your NLP session to predict the topic of tweets by examining the text content of the postings. In this project, you will create a model to classify the topic of pictures used in the tweets to help predict the topic of the tweets later. Your model from the NLP session and this one later can be used to predict a tweet's topic by examining both textual and the visual content of the postings.\n",
    "\n",
    "You will first execute Step 1 to pull the images from the corresponding URL address of each image contained in the tweets. These images are already labeled manually by human editors in terms of whether the images belong to `Nature` topic or not. The label `1` means the image belongs to the nature topic and `2` means otherwise.\n",
    "\n",
    "In Step 2, you will create a classification algorithm. Please divide the dataset into train and test datasets. You may use your train dataset to validate the accuracy of your model when tuning up the hyperparametrs of your model. After finalizing training your model, test it on your test dataset and report its accuracy. You may use different accuracy metrics. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd5ea30-2ce8-42bd-8139-d8b6ee492fca",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 1: Download the images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "550425a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging, os\n",
    "from _logging import set_logging\n",
    "from _metrics import display_metrics\n",
    "from _pckle import save_pickle_object, load_pickle_object\n",
    "from _utility import gl, get_perc\n",
    "\n",
    "set_logging(logging)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a21af23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_photo_urls():\n",
    "    df_photo_urls = load_pickle_object(gl.pkl_df_photo_urls)\n",
    "    if df_photo_urls.empty == False:\n",
    "        logging.info(\"Topic assigned Photo Urls retrieved from storage\")\n",
    "        return df_photo_urls\n",
    "\n",
    "    logging.info(\"Topic assigned Photo Urls not currently stored\")\n",
    "    filepath = os.path.join(\"Files\", \"tweet_data.csv\")\n",
    "    logging.info(f\"Read data from {filepath}\")\n",
    "    df_tweets_all = pd.read_csv(filepath)\n",
    "    # remove tweets with no photo urls\n",
    "    df_tweets = df_tweets_all[~df_tweets_all[gl.photoUrl].isnull()]\n",
    "    # select only relevant columns\n",
    "    df_photo_urls = df_tweets[[gl.photoUrl, gl.topic]].copy()\n",
    "    # we are interested if the topic is or is not Nature, so add a flag column\n",
    "    df_topic = pd.get_dummies(df_photo_urls[gl.topic], columns=[gl.topic])\n",
    "    df_photo_urls[gl.is_nature] = df_topic[gl.nature]\n",
    "    save_pickle_object(df_photo_urls, gl.pkl_df_photo_urls)\n",
    "    return df_photo_urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e947520a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-30 21:10:38,907 | INFO : Loading pickle file from: pickle\\pkl_df_photo_urls.pkl\n",
      "2023-01-30 21:10:38,962 | INFO : Topic assigned Photo Urls retrieved from storage\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>photoUrl</th>\n",
       "      <th>topicName</th>\n",
       "      <th>IsNature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://pbs.twimg.com/media/Dtx8SiIWkAImVsb.jpg</td>\n",
       "      <td>Business</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://pbs.twimg.com/media/Dtx8yTyW4AEciqP.jpg</td>\n",
       "      <td>Business</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://pbs.twimg.com/media/Dtx83JvX4AE48aw.jpg</td>\n",
       "      <td>Business</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>https://pbs.twimg.com/media/DtyCu-ZXgAUimt7.jpg</td>\n",
       "      <td>Business</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>https://pbs.twimg.com/media/DtyA7KSW4AA5deF.jpg</td>\n",
       "      <td>Business</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>https://pbs.twimg.com/media/DtyAKObXQAAPUSN.jpg</td>\n",
       "      <td>Business</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>https://pbs.twimg.com/media/Dts0d_vWkAARiHg.jpg</td>\n",
       "      <td>Animal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>https://pbs.twimg.com/media/DtyDOo0U8AAEl_o.jpg</td>\n",
       "      <td>Animal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>https://pbs.twimg.com/media/DtuIrMXWoAA5Wve.jpg</td>\n",
       "      <td>Nature</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>https://pbs.twimg.com/media/Dcnhi_FXcAAQPXk.jpg</td>\n",
       "      <td>Nature</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>https://pbs.twimg.com/media/DttX-ubUcAUGp4S.jpg</td>\n",
       "      <td>Travel</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>https://pbs.twimg.com/media/DttMJZDUwAEe-4L.jpg</td>\n",
       "      <td>Travel</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>https://pbs.twimg.com/media/Dtusrd2V4AAS5cD.jpg</td>\n",
       "      <td>Interesting</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>https://pbs.twimg.com/media/Dtx5V7bW4AAA5CK.jpg</td>\n",
       "      <td>Memes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>https://pbs.twimg.com/media/DtyIco-XcAA02Qp.jpg</td>\n",
       "      <td>Business</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           photoUrl    topicName  IsNature\n",
       "0   https://pbs.twimg.com/media/Dtx8SiIWkAImVsb.jpg     Business         0\n",
       "1   https://pbs.twimg.com/media/Dtx8yTyW4AEciqP.jpg     Business         0\n",
       "6   https://pbs.twimg.com/media/Dtx83JvX4AE48aw.jpg     Business         0\n",
       "15  https://pbs.twimg.com/media/DtyCu-ZXgAUimt7.jpg     Business         0\n",
       "21  https://pbs.twimg.com/media/DtyA7KSW4AA5deF.jpg     Business         0\n",
       "28  https://pbs.twimg.com/media/DtyAKObXQAAPUSN.jpg     Business         0\n",
       "40  https://pbs.twimg.com/media/Dts0d_vWkAARiHg.jpg       Animal         0\n",
       "42  https://pbs.twimg.com/media/DtyDOo0U8AAEl_o.jpg       Animal         0\n",
       "44  https://pbs.twimg.com/media/DtuIrMXWoAA5Wve.jpg       Nature         1\n",
       "47  https://pbs.twimg.com/media/Dcnhi_FXcAAQPXk.jpg       Nature         1\n",
       "48  https://pbs.twimg.com/media/DttX-ubUcAUGp4S.jpg       Travel         0\n",
       "49  https://pbs.twimg.com/media/DttMJZDUwAEe-4L.jpg       Travel         0\n",
       "56  https://pbs.twimg.com/media/Dtusrd2V4AAS5cD.jpg  Interesting         0\n",
       "58  https://pbs.twimg.com/media/Dtx5V7bW4AAA5CK.jpg        Memes         0\n",
       "71  https://pbs.twimg.com/media/DtyIco-XcAA02Qp.jpg     Business         0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_photo_urls = get_photo_urls()\n",
    "df_photo_urls.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78b4dfda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-30 21:12:34,957 | INFO : There are 277896 photos, of which 10615 (3.82%) are of Nature\n"
     ]
    }
   ],
   "source": [
    "total_urls = len(df_photo_urls)\n",
    "total_is_nature = sum(df_photo_urls[gl.is_nature])\n",
    "perc_nature = get_perc(total_is_nature, total_urls)\n",
    "logging.info(f\"There are {total_urls} photos, of which {total_is_nature} ({perc_nature}%) are of Nature\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2260d87",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3124b18c-b780-4d90-bdc9-f8ffb2f3c637",
   "metadata": {},
   "source": [
    "## Step 2: Classifier\n",
    "\n",
    "Develop a classifier for two categories. Create the necessary folders for the test and train datasets. Either create your own model or tranfer a model and revise it. Make sure you incorporate regularization, callbacks, etc., and use data augmentation. Since images may not be so distinct with respect to their categories, you may not get the same kind of performance you had in your assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690cff5b-0a25-434a-9961-ed17ab7ea3ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b41ba045e83f0be7a0a86cbeef029bed6bb1f3047ea5aef815a52ba8b6ba543c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
