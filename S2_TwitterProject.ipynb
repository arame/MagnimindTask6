{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Classifier\n",
    "\n",
    "Develop a classifier for two categories. Create the necessary folders for the test and train datasets. Either create your own model or tranfer a model and revise it. Make sure you incorporate regularization, callbacks, etc., and use data augmentation. Since images may not be so distinct with respect to their categories, you may not get the same kind of performance you had in your assignments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.models import ResNet18_Weights\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from collections import deque\n",
    "from pathlib import Path\n",
    "import logging, os, glob, sys\n",
    "from _logging import set_logging\n",
    "from _metrics import display_metrics\n",
    "from _pckle import save_pickle_object, load_pickle_object\n",
    "from _utility import gl, get_perc, get_dictionaries_from_list\n",
    "from _model import train_model\n",
    "\n",
    "set_logging(logging)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"Business\", \"Other\"]\n",
    "dict_classes, dict_classes_rev = get_dictionaries_from_list(classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH=256\n",
    "IMAGE_HEIGHT=256\n",
    "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "batch_size = 32\n",
    "batch_size_for_display = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loader(dataset, batch_size, root_dir):\n",
    "    # Upsampling for imbalanced dataset\n",
    "    class_weights = []\n",
    "    for root, subdir, files in os.walk(root_dir):\n",
    "        if len(files) > 0:\n",
    "            # We want more weighting for classes with a smaller number of images\n",
    "            # To acheive this, take the inverse of the number of files for that classes\n",
    "            class_weights.append(1/len(files)) \n",
    "             \n",
    "    sample_weights = [0] * len(dataset)     # This initialises a vector with zeros\n",
    "    for i, (images, label) in enumerate(dataset):\n",
    "        class_weight = class_weights[label]\n",
    "        sample_weights[i] = class_weight\n",
    "    sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, sampler=sampler)\n",
    "    return loader\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\lib\\site-packages\\PIL\\Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-04 07:16:51,333 | INFO : Saving pickle file from: pickle\\pkle_train_loader.pkl\n",
      "2023-02-04 07:16:52,136 | INFO : Saving pickle file from: pickle\\pkle_val_loader.pkl\n",
      "2023-02-04 07:16:59,576 | INFO : Saving pickle file from: pickle\\pkle_test_loader.pkl\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3377: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# See S3_TwitterProject_mean_and_std for calculations of mean and standard deviation\n",
    "_mean = [0.5117, 0.4919, 0.4784]\n",
    "_std = [0.3312, 0.3193, 0.3272]\n",
    "_transform = transforms.Compose(\n",
    "    [transforms.Resize([IMAGE_WIDTH, IMAGE_HEIGHT]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(torch.Tensor(_mean), torch.Tensor(_std))]\n",
    ")\n",
    "root_dir = \"Images\"\n",
    "_dataset = datasets.ImageFolder(root=root_dir, transform=_transform)\n",
    "size = _dataset.__len__()\n",
    "test_size = int(size * 0.05)\n",
    "new_size = size - test_size\n",
    "train_size = int(new_size * 0.8)\n",
    "val_size = new_size - train_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(_dataset, lengths=[train_size, val_size, test_size])\n",
    "display_loader = DataLoader(dataset = _dataset, batch_size=batch_size_for_display, shuffle=True)\n",
    "train_loader = get_loader(train_dataset, batch_size, root_dir)\n",
    "val_loader = get_loader(val_dataset, batch_size, root_dir)\n",
    "test_loader = get_loader(test_dataset, batch_size, root_dir)\n",
    "save_pickle_object(train_loader, gl.pkl_train_loader)\n",
    "save_pickle_object(val_loader, gl.pkl_val_loader)\n",
    "save_pickle_object(test_loader, gl.pkl_test_loader)\n",
    "sys.exit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The upsampling of the data loaders takes a long time, so the next part for the model training can be found in <br>\n",
    "S4_TwitterProject.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
