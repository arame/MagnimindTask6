{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-07 08:16:15,561 | INFO : Cuda is available: True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.models import ResNet18_Weights\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import logging, os, glob\n",
    "from _logging import set_logging\n",
    "from _metrics import display_metrics\n",
    "from _pckle import save_pickle_object, load_pickle_object\n",
    "from _utility import gl, get_perc, get_dictionaries_from_list\n",
    "from _model import train_model\n",
    "from _graph import accuracy_loss_graph\n",
    "\n",
    "set_logging(logging)\n",
    "logging.info(f\"Cuda is available: {torch.cuda.is_available()}\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "classes = [\"Business\", \"Other\"]\n",
    "dict_classes, dict_classes_rev = get_dictionaries_from_list(classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-07 08:16:16,086 | INFO : Loading pickle file from: pickle\\pkle_train_loader.pkl\n",
      "2023-02-07 08:16:16,523 | INFO : Loading pickle file from: pickle\\pkle_val_loader.pkl\n"
     ]
    }
   ],
   "source": [
    "train_loader = load_pickle_object(gl.pkl_train_loader)\n",
    "val_loader = load_pickle_object(gl.pkl_val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-07 08:16:16,683 | INFO : Train dataset size: 35046\n",
      "2023-02-07 08:16:16,683 | INFO : Val dataset size: 8762\n"
     ]
    }
   ],
   "source": [
    "dataloaders = {\"train\": train_loader, \"val\": val_loader}\n",
    "train_dataset_size = len(train_loader.dataset)\n",
    "val_dataset_size = len(val_loader.dataset)\n",
    "dataset_sizes = {\"train\": train_dataset_size, \"val\": val_dataset_size}\n",
    "logging.info(f\"Train dataset size: {train_dataset_size}\")\n",
    "logging.info(f\"Val dataset size: {val_dataset_size}\")\n",
    "# Get the latest version of the Resnet weights and freeze the layers\n",
    "model_conv = torchvision.models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
    "model_conv = model_conv.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Only parameters of final layer are being optimized\n",
    "optimizer_ft = optim.Adam(model_conv.fc.parameters(), lr=0.0001)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Checkpoint and Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(gl.chk_dir) == False:\n",
    "    os.mkdir(gl.chk_dir)\n",
    "    \n",
    "checkpoint_path = os.path.join(gl.chk_dir, gl.chk_resnet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint_path, model_conv, optimizer_ft):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model_conv.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    optimizer_ft.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    epoch = checkpoint[\"epoch\"]\n",
    "    loss = checkpoint[\"loss\"]\n",
    "    return checkpoint, model_conv, optimizer_ft, epoch, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-07 08:16:23,677 | INFO : Epoch 1/25\n",
      "2023-02-07 08:16:23,678 | INFO : ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\lib\\site-packages\\PIL\\Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-07 09:28:45,351 | INFO : train Loss: 0.5820 Acc: 0.6839\n",
      "2023-02-07 09:43:00,496 | INFO : val Loss: 0.5273 Acc: 0.7311\n",
      "Best validation accuracy: 0.7311116183519745\n",
      "Saving best model for epoch: 1\n",
      "2023-02-07 09:43:08,021 | INFO : Epoch 2/25\n",
      "2023-02-07 09:43:08,022 | INFO : ----------\n",
      "2023-02-07 10:48:40,358 | INFO : train Loss: 0.5158 Acc: 0.7446\n",
      "2023-02-07 11:02:22,562 | INFO : val Loss: 0.4962 Acc: 0.7547\n",
      "Best validation accuracy: 0.7547363615612874\n",
      "Saving best model for epoch: 2\n",
      "2023-02-07 11:02:23,875 | INFO : Epoch 3/25\n",
      "2023-02-07 11:02:23,876 | INFO : ----------\n",
      "2023-02-07 11:59:15,492 | INFO : train Loss: 0.4959 Acc: 0.7618\n",
      "2023-02-07 12:11:17,975 | INFO : val Loss: 0.4845 Acc: 0.7684\n",
      "Best validation accuracy: 0.768431864871034\n",
      "Saving best model for epoch: 3\n",
      "2023-02-07 12:11:19,557 | INFO : Epoch 4/25\n",
      "2023-02-07 12:11:19,559 | INFO : ----------\n"
     ]
    }
   ],
   "source": [
    "load_checkpoint_flag = False\n",
    "if load_checkpoint_flag:\n",
    "    checkpoint, model_conv, optimizer_ft, epoch, loss = \\\n",
    "        load_checkpoint(checkpoint_path, model_conv, optimizer_ft)\n",
    "    \n",
    "patience = 2\n",
    "model_conv, epoch_train_accuracy, epoch_train_losses, epoch_val_accuracy, epoch_val_losses = \\\n",
    "    train_model(model_conv, logging, criterion, optimizer_ft, exp_lr_scheduler, dataloaders, dataset_sizes, \n",
    "                         checkpoint_path, patience, num_epochs=25)\n",
    "\n",
    "save_pickle_object(model_conv, gl.pkl_model_conv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'base (Python 3.9.12)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "accuracy_loss_graph(epoch_train_accuracy, epoch_train_losses, epoch_val_accuracy, epoch_val_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
