{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-06 08:38:20,127 | INFO : Cuda is available: True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.models import ResNet18_Weights\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import logging, os, glob\n",
    "from _logging import set_logging\n",
    "from _metrics import display_metrics\n",
    "from _pckle import save_pickle_object, load_pickle_object\n",
    "from _utility import gl, get_perc, get_dictionaries_from_list\n",
    "from _model import train_model\n",
    "from _graph import accuracy_loss_graph\n",
    "\n",
    "set_logging(logging)\n",
    "logging.info(f\"Cuda is available: {torch.cuda.is_available()}\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "classes = [\"Business\", \"Other\"]\n",
    "dict_classes, dict_classes_rev = get_dictionaries_from_list(classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-06 08:38:20,219 | INFO : Loading pickle file from: pickle\\pkle_train_loader.pkl\n",
      "2023-02-06 08:38:20,826 | INFO : Loading pickle file from: pickle\\pkle_val_loader.pkl\n",
      "2023-02-06 08:38:20,904 | INFO : Loading pickle file from: pickle\\pkle_test_loader.pkl\n"
     ]
    }
   ],
   "source": [
    "train_loader = load_pickle_object(gl.pkl_train_loader)\n",
    "val_loader = load_pickle_object(gl.pkl_val_loader)\n",
    "test_loader = load_pickle_object(gl.pkl_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, _mean, _std, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array(_mean)\n",
    "    std = np.array(_std)\n",
    "    inp = std * inp + mean  # denormalise\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, dataloaders, classes, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title(f'predicted: {classes[preds[j]]}')\n",
    "                imshow(inputs.cpu().data[j])\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-06 08:38:21,114 | INFO : Train dataset size: 35046\n",
      "2023-02-06 08:38:21,115 | INFO : Val dataset size: 8762\n"
     ]
    }
   ],
   "source": [
    "dataloaders = {\"train\": train_loader, \"val\": val_loader}\n",
    "train_dataset_size = len(train_loader.dataset)\n",
    "val_dataset_size = len(val_loader.dataset)\n",
    "dataset_sizes = {\"train\": train_dataset_size, \"val\": val_dataset_size}\n",
    "logging.info(f\"Train dataset size: {train_dataset_size}\")\n",
    "logging.info(f\"Val dataset size: {val_dataset_size}\")\n",
    "# Get the latest version of the Resnet weights and freeze the layers\n",
    "model_conv = torchvision.models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
    "model_conv = model_conv.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Only parameters of final layer are being optimized\n",
    "optimizer_ft = optim.Adam(model_conv.fc.parameters(), lr=0.0001)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Checkpoint and Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(gl.chk_dir) == False:\n",
    "    os.mkdir(gl.chk_dir)\n",
    "    \n",
    "checkpoint_path = os.path.join(gl.chk_dir, gl.chk_resnet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint_path, model_conv, optimizer_ft):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model_conv.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    optimizer_ft.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    epoch = checkpoint[\"epoch\"]\n",
    "    loss = checkpoint[\"loss\"]\n",
    "    return checkpoint, model_conv, optimizer_ft, epoch, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-06 08:38:23,201 | INFO : Epoch 1/25\n",
      "2023-02-06 08:38:23,202 | INFO : ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\lib\\site-packages\\PIL\\Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-06 09:26:47,423 | INFO : train Loss: 0.5771 Acc: 0.6934\n",
      "2023-02-06 09:39:06,412 | INFO : val Loss: 0.5213 Acc: 0.7404\n",
      "Best validation accuracy: 0.7403560830860534\n",
      "Saving best model for epoch: 1\n",
      "2023-02-06 09:39:09,069 | INFO : Epoch 2/25\n",
      "2023-02-06 09:39:09,070 | INFO : ----------\n",
      "2023-02-06 10:19:31,413 | INFO : train Loss: 0.5116 Acc: 0.7492\n",
      "2023-02-06 10:36:29,096 | INFO : val Loss: 0.4978 Acc: 0.7598\n",
      "EarlyStopping counter: 1 out of 2\n",
      "2023-02-06 10:36:29,787 | INFO : Early stopping for epoch: 2\n",
      "2023-02-06 10:36:29,788 | INFO : Training complete in 118m 7s\n",
      "2023-02-06 10:36:29,788 | INFO : Best val Acc: 0.000000\n",
      "2023-02-06 10:36:31,009 | INFO : Saving pickle file from: pickle\\model_conv.pkl\n"
     ]
    }
   ],
   "source": [
    "load_checkpoint_flag = False\n",
    "if load_checkpoint_flag:\n",
    "    checkpoint, model_conv, optimizer_ft, epoch, loss = \\\n",
    "        load_checkpoint(checkpoint_path, model_conv, optimizer_ft)\n",
    "    \n",
    "patience = 2\n",
    "model_conv = train_model(model_conv, logging, criterion, optimizer_ft, exp_lr_scheduler, dataloaders, dataset_sizes, \n",
    "                         checkpoint_path, patience, num_epochs=25)\n",
    "\n",
    "save_pickle_object(model_conv, gl.pkl_model_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'training'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\mma\\Task6\\MagnimindTask6\\S4_TwitterProject.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/mma/Task6/MagnimindTask6/S4_TwitterProject.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m visualize_model(model_conv, dataloaders, classes)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/mma/Task6/MagnimindTask6/S4_TwitterProject.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mioff()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/mma/Task6/MagnimindTask6/S4_TwitterProject.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "\u001b[1;32md:\\mma\\Task6\\MagnimindTask6\\S4_TwitterProject.ipynb Cell 10\u001b[0m in \u001b[0;36mvisualize_model\u001b[1;34m(model, dataloaders, classes, num_images)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/mma/Task6/MagnimindTask6/S4_TwitterProject.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvisualize_model\u001b[39m(model, dataloaders, classes, num_images\u001b[39m=\u001b[39m\u001b[39m6\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/mma/Task6/MagnimindTask6/S4_TwitterProject.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     was_training \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtraining\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/mma/Task6/MagnimindTask6/S4_TwitterProject.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     model\u001b[39m.\u001b[39meval()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/mma/Task6/MagnimindTask6/S4_TwitterProject.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     images_so_far \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'training'"
     ]
    }
   ],
   "source": [
    "visualize_model(model_conv, dataloaders, classes)\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a54084e6b208ee8d1ce3989ffc20924477a5f55f5a43e22e699a6741623861e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
