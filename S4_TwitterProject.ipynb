{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-05 20:41:04,039 | INFO : Cuda is available: True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.models import ResNet18_Weights\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import logging, os, glob\n",
    "from _logging import set_logging\n",
    "from _metrics import display_metrics\n",
    "from _pckle import save_pickle_object, load_pickle_object\n",
    "from _utility import gl, get_perc, get_dictionaries_from_list\n",
    "from _model import train_model\n",
    "\n",
    "set_logging(logging)\n",
    "logging.info(f\"Cuda is available: {torch.cuda.is_available()}\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "classes = [\"Business\", \"Other\"]\n",
    "dict_classes, dict_classes_rev = get_dictionaries_from_list(classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-05 20:41:04,128 | INFO : Loading pickle file from: pickle\\pkle_train_loader.pkl\n",
      "2023-02-05 20:41:04,661 | INFO : Loading pickle file from: pickle\\pkle_val_loader.pkl\n",
      "2023-02-05 20:41:04,716 | INFO : Loading pickle file from: pickle\\pkle_test_loader.pkl\n"
     ]
    }
   ],
   "source": [
    "train_loader = load_pickle_object(gl.pkl_train_loader)\n",
    "val_loader = load_pickle_object(gl.pkl_val_loader)\n",
    "test_loader = load_pickle_object(gl.pkl_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, _mean, _std, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array(_mean)\n",
    "    std = np.array(_std)\n",
    "    inp = std * inp + mean  # denormalise\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, dataloaders, classes, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title(f'predicted: {classes[preds[j]]}')\n",
    "                imshow(inputs.cpu().data[j])\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-05 20:41:04,962 | INFO : Train dataset size: 35046\n",
      "2023-02-05 20:41:04,963 | INFO : Val dataset size: 8762\n"
     ]
    }
   ],
   "source": [
    "dataloaders = {\"train\": train_loader, \"val\": val_loader}\n",
    "train_dataset_size = len(train_loader.dataset)\n",
    "val_dataset_size = len(val_loader.dataset)\n",
    "dataset_sizes = {\"train\": train_dataset_size, \"val\": val_dataset_size}\n",
    "logging.info(f\"Train dataset size: {train_dataset_size}\")\n",
    "logging.info(f\"Val dataset size: {val_dataset_size}\")\n",
    "# Get the latest version of the Resnet weights and freeze the layers\n",
    "model_conv = torchvision.models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
    "model_conv = model_conv.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Only parameters of final layer are being optimized\n",
    "optimizer_ft = optim.Adam(model_conv.fc.parameters(), lr=0.0001)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Checkpoint and Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(gl.chk_dir) == False:\n",
    "    os.mkdir(gl.chk_dir)\n",
    "    \n",
    "checkpoint_path = os.path.join(gl.chk_dir, gl.chk_resnet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint_path, model_conv, optimizer_ft):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model_conv.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    optimizer_ft.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    epoch = checkpoint[\"epoch\"]\n",
    "    loss = checkpoint[\"loss\"]\n",
    "    return checkpoint, model_conv, optimizer_ft, epoch, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-05 20:41:07,676 | INFO : Epoch 1/25\n",
      "2023-02-05 20:41:07,677 | INFO : ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\lib\\site-packages\\PIL\\Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-05 21:42:29,729 | INFO : train Loss: 0.5674 Acc: 0.7014\n",
      "2023-02-05 21:56:04,320 | INFO : val Loss: 0.5272 Acc: 0.7431\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\mma\\Task6\\MagnimindTask6\\S4_TwitterProject.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/mma/Task6/MagnimindTask6/S4_TwitterProject.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     checkpoint, model_conv, optimizer_ft, epoch, loss \u001b[39m=\u001b[39m \\\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/mma/Task6/MagnimindTask6/S4_TwitterProject.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         load_checkpoint(checkpoint_path, model_conv, optimizer_ft)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/mma/Task6/MagnimindTask6/S4_TwitterProject.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m patience \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/mma/Task6/MagnimindTask6/S4_TwitterProject.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m model_conv \u001b[39m=\u001b[39m train_model(model_conv, logging, criterion, optimizer_ft, exp_lr_scheduler, dataloaders, dataset_sizes, \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/mma/Task6/MagnimindTask6/S4_TwitterProject.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                          checkpoint_path, patience, num_epochs\u001b[39m=\u001b[39;49m\u001b[39m25\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/mma/Task6/MagnimindTask6/S4_TwitterProject.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m save_pickle_object(model_conv, gl\u001b[39m.\u001b[39mpkl_model_conv)\n",
      "File \u001b[1;32md:\\mma\\Task6\\MagnimindTask6\\_model.py:64\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, logging, criterion, optimizer, scheduler, dataloaders, dataset_sizes, checkpoint_path, patience, num_epochs)\u001b[0m\n\u001b[0;32m     61\u001b[0m                 logging\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEarly stopping for epoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     62\u001b[0m                 \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m             save_best_model(epoch_acc, epoch, model, optimizer, criterion, logging)\n\u001b[0;32m     66\u001b[0m     \u001b[39mprint\u001b[39m()\n\u001b[0;32m     68\u001b[0m time_elapsed \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m since\n",
      "File \u001b[1;32md:\\mma\\Task6\\MagnimindTask6\\_checkpoint.py:23\u001b[0m, in \u001b[0;36mSaveBestModel.__call__\u001b[1;34m(self, current_valid_accuracy, epoch, model, optimizer, criterion, logging)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mif\u001b[39;00m current_valid_accuracy \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_valid_accuracy:\n\u001b[0;32m     22\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_valid_accuracy \u001b[39m=\u001b[39m current_valid_accuracy\n\u001b[1;32m---> 23\u001b[0m     logging(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39mBest validation accuracy: \u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbest_valid_accuracy\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     24\u001b[0m     logging(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mSaving best model for epoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     25\u001b[0m     torch\u001b[39m.\u001b[39msave({\n\u001b[0;32m     26\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m'\u001b[39m: epoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m     27\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mmodel_state_dict\u001b[39m\u001b[39m'\u001b[39m: model\u001b[39m.\u001b[39mstate_dict(),\n\u001b[0;32m     28\u001b[0m         \u001b[39m'\u001b[39m\u001b[39moptimizer_state_dict\u001b[39m\u001b[39m'\u001b[39m: optimizer\u001b[39m.\u001b[39mstate_dict(),\n\u001b[0;32m     29\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m: criterion,\n\u001b[0;32m     30\u001b[0m         }, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheckpoint_path)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "load_checkpoint_flag = False\n",
    "if load_checkpoint_flag:\n",
    "    checkpoint, model_conv, optimizer_ft, epoch, loss = \\\n",
    "        load_checkpoint(checkpoint_path, model_conv, optimizer_ft)\n",
    "    \n",
    "patience = 2\n",
    "model_conv = train_model(model_conv, logging, criterion, optimizer_ft, exp_lr_scheduler, dataloaders, dataset_sizes, \n",
    "                         checkpoint_path, patience, num_epochs=25)\n",
    "\n",
    "save_pickle_object(model_conv, gl.pkl_model_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'base (Python 3.9.12)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "visualize_model(model_conv, dataloaders, classes)\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
